\documentclass{IEEEtran}
%\documentclass{article}

\usepackage{graphicx}

\begin{document}
\title{WAN-in-Lab: Motivation, deployment and experiments}
\author{George S. Lee, Lachlan L. H. Andrew, Kevin (Ao) Tang and Steven H. Low}
\maketitle

\begin{abstract}
WAN-in-Lab is a hardware testbed for the design, development, testing
and evaluation of TCP protocols.  It uses real carrier-class networking
hardware to avoid the artifacts introduced by network emulation, while
being localized to allow detailed measurement of network performance.
This paper describes the structure of WAN-in-Lab, issues encountered,
and experimental results verifying the existence of multiple equilibria
in networks carrying heterogeneous protocols.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{section}{Introduction/Background}
It has recently become apparent that very high speed wide area
networks (WANs) are pushing the limits of existing protocols, such
as the transmission control protocol (TCP). This has led to many
proposed replacements for TCP \cite{FAST-NW}, \cite{FAST-INFOCOM}, [3], [4], [5], [6],
[7], [8], which must be evaluated, optimized and eventually developed
into the next generation of TCP. Although initial design and testing
can be performed using mathematical modeling and software simulation,
there is ultimately a need to implement the selected algorithms in real
networks. This project seeks to develop a test facility called WAN-in-Lab,
consisting of a complete WAN in a laboratory environment, which is to
be available for use by the global networking research community.

Developing protocols requires many forms of testing. Existing tools are
listed below, in decreasing order of abstraction. All of these play a role
in developing congestion control protocols. However, there is a big gap
between emulation and production networks, which WAN-in-Lab seeks to fill.

\begin{enumerate}
\item Mathematical modeling can explore infinite classes of networks
but  requires simplification of actual protocols, ignoring important
implementation issues.

\item Simulation is a very flexible first step in evaluating
proposals. However, simulating high speed networks is many times slower
than real-time and does not allow testing and optimization of actual
implementations.

\item Emulation of large delays using Dummynet or Netem also works well
for links below 1 Gbit/s. Unfortunately, software emulation introduces
artifacts, notably in the form of jitter, which become increasingly
severe at higher link rates.

\item Production networks are the ultimate testing ground for new
protocols, allowing black-box evaluations through limited end-to-end
measurements. This is suitable for tests which will not disrupt other
traffic, but not for testing many failure modes, such as heavily
overloaded networks, or equipment failures.
\end{enumerate}

\end{section}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{section}{Infrastructure Planning and Facilities}
As this is an infrastructure project, there needs to be a tremendous
amount of planning due to the complexity of WIL.  This section describes
the current status of the WAN-in-Lab hardware.

\begin{subsection}{Hardware: What we need to build targets:}

In order to build a meaningful WAN testbed we planned to have a v{\bf FINISH}

1ms  200ms, 50+ servers, rich/interesting topology, common WAN hardware,
ability to reconfigure
\end{subsection}

\begin{subsection}{Design:}
\begin{subsubsection}{Layers 1 and 2 - ONS:}
WILs core network consists of 13 Cisco Optical Network Systems(ONS)
15454 Multiservice Transport Platform(MSTP) interconnected by 24 spools
of 100km Corning LEAF single mode fiber. The ONS 15454s are designed for
metro and regional DWDM networks up to 40Gbps. WIL has ONSs populated
with OC192 transponders, optical add/drop multiplexers and amplifers,
and multi-channel OC48 muxponders.

To maximize efficiency, ONS uses Wavelength Division Multiplexing(WDM)
to achieve 40Gbps line rate. Each ONS configured as an endpoint uses
an Optical Add Drop Multiplexer(OADM) to merge or separate four 10Gbps
OC192 streams from the fiber. Each one of these 10Gbps streams is then
divided up into four separate OC48 streams using a Muxponder card.

The 40Gbps multiplexed signal leaves the endpoint ONS, traverses 100km
of fiber, and is received by another ONS configured as an optical
amplifier. The regenerated 40Gbps signal is then sent over another
100km of fiber to be received by another endpoint ONS. This three ONS
configuration uses a total of 4 spools spanning of 200km and up to 16
separate OC48 channel capacity.

To increase delay the OC48 channels can be connected back-to-back such
that a single OC48 stream must traverse 16 times before it leaves
the system. This configuration yields 3200km of total distance and
approximately 32ms of delay. Currently, WIL has three of these looped
ONS configurations yielding a grand total of about 100ms.
\end{subsubsection}

\begin{subsubsection}{Layer 3 - Routers}
WIL has four Cisco 7609 series routers designed for high end Metropolitan
Ethernet and ISPs. The routers are populated with OSM-1OC48-POS-SS+  and
OSM-1OC48-POS-SL blades that support most enhanced WAN features such as
various QoS schemes, VLANs, and VPNs. The OC48 blades are connected into
the ONS depending on the network topology. Each router also has multiple
1Gbps Ethernet connections for servers and traffic generators.
\end{subsubsection}
\end{subsection}

\begin{subsection}{Servers}
WIL has over 20 Dual Intel Xeon 1U servers that generate traffic over the
network. The servers are configured for PXE network boot such that they
can be reconfigured quickly with different kernels and settings. Each
server has at least two network interfaces: one for experiments and one
for management. Furthermore, each server is connected to a console server
incase network connectivity has failed.
\end{subsection}

\begin{subsection}{Managementment network 192.168.X.X}
Each network device in WIL has an Ethernet manage port that resides on the
private network 192.168.0.0/24. In order to house all of this equipment,
WIL hardware has been mounted on ten 8 foot 51U 19inch 4 post racks linked
side by side. Each rack has been assigned a number that corresponds to
the IP addresses allowed. For example, the left most rack is rack 1 and
has 192.168.1.0/24 allocated to it. Several management servers have been
installed on this network for DHCP, DNS, remote access, file storage, etc.
\end{subsection}

\begin{subsection}{Machine room design}
When WIL was first constructed we knew would encounter a lot of
difficulties due to the complexity of the design. In order to build a lab
of this size we would need at least 800 sq. ft. of space that was nearby,
had enough electrical power, chilled water for AC, noise isolation,
and secure.

Due to the wiring complexity of WIL, the physical layout is critical and
should visually represent the hierarchy of network. On the outer racks,
1 and 10, they are reserved for servers and traffic generators. On racks 2  and 
9, reside the routers that the servers will connect into. Naturally,
racks 3, 4, 7, and 8, house all of the ONS chassis that the routers
connect into. Finally, the middle two racks 5 and 6, contain all of the
fiber spools and central patch panels.

On every rack a choice of AC 120/240V or DC 48V electricity is available
via a ceiling drop. Copper and fiber network connectivity is provided on
the first 3U of each rack that route to the center patch panel. Cables
are individual number and color coded to each rack such that managing
several hundred cables is possible.
\end{subsection}

\begin{subsection}{Automatic network topology reconfigurability}
In January 2006, a Calient DiamondWave PXC 144x144 optical switch was
added to WIL. All OC48 ONS spans in groups of 200km, 400km, 800km,
and 1600km along with all OC48 interfaces on the routers have been
attached to the optical switch. The optical switch will enable WIL to
automatically change any OC48 fiber path resulting in minor or major
changes network topology in a just a couple of seconds.

Rerouting is particularly important for delay-based protocols such
as FAST.  More vitally, this capability also allows the delay between
routers to be adjusted from 0ms to 100ms (round trip), in increments
of 2ms(200km).  Using IP loopbacks, it is possible to achieve delays
up to 125ms, corresponding to trans-Atlantic distances.  TCP protocols
behave very differently depending on the round trip delays, and so it is
very important to be able to test and evaluate them in this wide range
of conditions.

Automatic network reconfiguration for 1Gbps copper and multimode fiber
based servers are provided by Cisco 3950 switches using VLANs.

When a network topology change occurs, WIL must also reconfigure
IP addresses and subnets for the network to function properly. We
have developed an IP assignment scheme that helps us hundreds of
interfaces. The WIL experiment network is a bunch of class C networks
in the private 10.0.0.0/8 network. On each interface the first octet
is always 10. The second octet is 0 if it is an interface on a router,
1 if it is a server connected to router 1, 2 if it is a server connected
to router 2, and so on.

For router interfaces, 10.0.X.X, the third octet is a double digit number
that derived from each of the connected routers.  The fourth octet is the
router number the interface is located on. For example, the interface
on router 1 between router 1 and 2 would be 10.0.12.1. Likewise, the
interface on router 2 between router 1 and 2 would be 10.0.12.2. This
guarantees that both interfaces will always reside in the same class
C subnet.

For servers interfaces, the third octet is a double digit number that is
derived from the physical slot number on the router and the port number
on that card. The fourth octet is 1 if it is the interface on the router
and is 2 if it is the interface on the server. For example, the router
interface connected to a server on 4th Ethernet port on slot 2 on router
1 would be 10.1.24.1. Likewise, the respective server interface would
be 10.1.24.2. Again, this IP scheme will guarantee that they will be in
the same subnet.
\end{subsection}

\begin{subsection}{Scripted Configuration}
In order to fully automate the reconfiguration of WILs network topology,
we have created scripts to execute those changes in sequence. WIL-NS is
the main management server which oversees the network topology state. In
addition it communicates to the optical switch, copper switch, routers,
and servers, via TL1 and other scripting languages to initiate a change.
\end{subsection}

\end{section}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{section}{Difficulties encountered}
Many researchers need to build testbeds.  This section describes the
pitfalls faced by WAN-in-Lab, to help other researchers avoid repeating
our experiences. Time line of stuff that was installed, budget, working
system with key features before

\begin{subsection}{Construction Difficulties}

Budget, allocation of cards, failure rates, wire management,

Maintainence

Dead disks, dead power supplies, dead cards,
\end{subsection}

\begin{subsection}{Configuration Inflexibility}
The initial motivation for WAN-in-Lab was to provide a more realistic
network than a dummynet, but one in which we understood and could control
each component.  However, using commercial routers with no access to the
firmware and physical fibres for delay inevitably reduces the level of
control we have.  This section describes problems we found and how we
worked around them.

\begin{subsubsection}{Multiple buffers}: It is common to model a link as having a single buffer.
However, 7609 routers have multiple stages of buffering, which are not
clearly documented, and not configurable; in particular, the command
to configure the output buffer size executes without error, but does
not actually change the size of the buffer used.

{\bf Work around}: The
SS+ and POS-SL blades both support token-bucket traffic shaping, with
variable-sized buffers.  By shaping the traffic to below 2.5Gbit/s per
link, the buffer size can be controlled.
\end{subsubsection}

\begin{subsubsection}{Discrete buffer sizes}:
Buffer sizes cannot be set in increments of
one packet.  The size in packets must be a power of two, from 128 to
32k, or 18, 25 or 42.

{\bf Work around}: None; this is a typical artifact of
real routers, and we are interested in the behavior of protocols with
such restrictions.
\end{subsubsection}

\begin{subsubsection}{Delay granularity}: WAN-in-Labs delays are produced by passing data
multiple times over spools of fiber.  The granularity is at best the
delay due to a single fiber.  Moreover, there are 48 individual segments
to be switched in or out, requiring 96 optical switch ports, in addition
to those.

{\bf Work around}: Delay segments are hard-wired into groups of 1,
2, 4 or 8 segments, which can be switched as single units with a limited
 number of optical switch ports.
\end{subsubsection}

\begin{subsubsection}{Topologies and limited delay}:
The hardware supports a maximum delay
under 100ms, and only four OC48 links.  (Although this is many more
than the single link often used, there are interesting effects which
only become apparent with five or more links~\cite{Heterogeneous}.)

{\bf Work around}:
By setting static routes in the routers, virtual IP-level topologies
can be constructed which traverse the physical links multiple times (in
addition to the 16 loopbacks at layer 2), giving delays well over 100ms,
and allowing topologies of at least six hops.
\end{subsubsection}

\begin{subsubsection}{Combinations of features}: The IOS configuration language allows
multiple traffic shapers on a single port by assigning flows to
different access lists.  This would allow independent queues on each
virtual link using that interface. Although the SS+ and SL blades have
support for both access-lists and traffic shaping, they do not support
this combination.  This is a lesson for anyone constructing a network:
always check explicitly that your chosen combination of features will
work, rather than just ensuring that each is supported.

{\bf Work around}:
Do not virtualize bottleneck links.  Virtual links can still be used to
give increased delay, provided there is no traffic shaping on them.
\end{subsubsection}
\end{subsection}

\end{section}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{section}{Targeted Activities}
The aim of WAN-in-Lab is to provide a realistic but controlled
environment, which enables detailed monitoring of all aspects of
protocol operation. This will allow an integrated approach, where
theory development, implementation, experiments, and deployment inform
and influence each other intimately. WAN-in-Lab is an open resource,
intended for use by the entire networking community.

The hardware in WAN-in-Lab is generic and can be used for many aspects
of protocol development.  However, our goal is to continue to develop a
higher layer software infrastructure targeting performance benchmarking
of different TCP variants.  This will involve developing a measurement
capability which can identify the queueing and burstiness of traffic,
and correlate these measurements with the internal state of the protocols,
such as window sizes and timeout thresholds.

\end{section}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{section}{Example applications}
\begin{subsection}{Topologies}
WAN-in-Lab can implement a wide range of protocols using both its hardware
and software routers.  Considering only the hardware routers, it has four
core nodes, with degrees 1, 2, 2 and 3.  This yields a physical topology
of a three-node ring plus one attached node.  Although this topology is
irregular, deleting a link can yield a three hop-parking-lot topology,
a three-hop ring or a three-hop star.

A five-node, four-hop parking-lot topology can be obtained by virtualizing
the degree-three router using static routing tables.  This topology
uses each physical link only once, and so does not introduce any traffic
artifacts.

At the expense of slight artifacts, links can also be virtualized,
yielding up to a six-node parking-lot.  The artifact arises because
each physical link is used as the forward path for one virtual link
and the reverse path for another virtual link.  Thus, the queueing
(delay and loss) experienced by packets on one link is also experienced
by acknowledgements on a different link.  This artifact is harmless for
testing the functionality of protocol implementation, but must be avoided
for performance testing.  As noted above, delays can also be extended
by virtualising links; this does not introduce significant artifacts as
long as the virtual links are not bottlenecks.
\end{subsection}

\begin{subsection}{Bistability of heterogeneous protocols}
Many interesting phenomena only occur in networks of more than two hops.
One such is the possibility of multiple equilibrium rate allocations
between flows when delay-based and loss-based protocols are mixed
\cite{Heterogeneous}.  This has been observed in DummyNet networks,
and this paper presents results demonstrating it using WAN-in-Lab's hardware
routers.

\begin{subsubsection}{Experiment}
Multiple equilibria arise when the same traffic load can cause different
combinations of links to be bottlenecks.  Optimisation-based
analysis~\cite{Duality-model} shows that this cannot happen when all flows
respond to a common congestion signal (e.g. loss), even if their responses
differ, say the way H-TCP differs from Reno.  However, it can happen if
some protocols respond to loss and others to delay, in networks in which
some links can have high loss and low delay while others can have low loss and
high delay.

Consider the symmetric three link network show in Figure~\ref{f.network}.  The
links use Random Early Discard (RED), with the parameters on link 2 set for
low loss and high delay, but those on links 1 and 3 set for high loss and low
delay.

\begin{figure}
    \includegraphics[width=\columnwidth]{}
    \caption{Network with links with different loss/delay tradeoffs}
    \label{f.network}
\end{figure}

In this topology, it is possible for link 2 to be the sole bottleneck since it
carries the largest number of flows, or for links 1 and 3 to be bottlenecks
since they have the smallest capacity.  If all flows responded to the same
congestion signal and have concave ``utility'' functions, the bottleneck
assignment which maximises the protocols' aggregate utility will be the only
equilibrium.  With mixed feedback signals, with careful choice of parameters,
both are stable equilibria, and the system can be forced into either state
depending on the initial conditions.  In particular, if the 3-hop Reno flows
start first, they create sufficient delay in links 1 and 3 to force those links
to remain bottlenecks.  Conversely, if the 2-hop FAST flows start first, a
newly-arriving Reno flow will cause sufficient loss at link 2 that link 2 will
remain bottlenecked.

Note that these two equilibria correspond to different sets of bottleneck links.
This is more than just ``sustained unfairness'' due to old flows not making
room for new flows, although that is the way the system was forced into the
different equilibria.

The aim here is not to verify that these are indeed distinct equilibria, since
this was established in~\cite{Heterogeneous}, or to claim that delay is a
better or worse measure of congestion than delay is.
The aim is to show that WAN-in-Lab provides a new proving-ground for protocol
research, which can either verify or contradict results from DummyNet
experiments.
More specifically, this experiment aims to demonstrate that having
multiple equilibria is not simply an artifact of, say, the way that RED is
implemented in DummyNet, but can also be exhibited in a real network.
\end{subsubsection}

\begin{subsubsection}{Settings and Results}
Figures \ref{f.RenoFirst} and~\ref{f.FASTFirst} show traces of the aggregate
rate (calculated as window size\slash RTT) on each of the routes.  The
parameters used were as follows:

$w_q=2^{-16}$, exponential averaging interval

min\_th=300, max\_th=32000, p\_drop = 1/5  for links 1 and 3

min\_th=100, max\_th=1500, p\_drop = 1  for link 2

$\alpha = 10^5$ bytes, FAST not responding to loss

Delay of links 1 and 3: 14ms, delay of link 2: 21ms.

Two FAST flows traversing links 1 and 2, two traversing links 2 and 3, and 10
Reno flows traversing links 1, 2 and 3.

slow start limited by memory (to a level above the saw-tooth fluctuations of
Reno's normal behaviour).

\begin{figure}
    \includegraphics[width=\columnwidth]{FirstReno}
    \caption{Links 1 and 3 bottlenecked.  (Reno starting first.)}
    \label{f.RenoFirst}
\end{figure}
\begin{figure}
    \includegraphics[width=\columnwidth]{FirstFAST}
    \caption{Link 2 bottlenecked.  (FAST starting first.)}
    \label{f.FASTFirst}
\end{figure}
\end{subsubsection}

\begin{subsubsection}{Lessons}
The parameters used in this experiment, notably the RED loss rates, were
significantly different from those used in~\cite{Heterogeneous}.  Initially,
the parameters of~\cite{Heterogeneous} were used, but did not yield distinct
equilibria.  This demonstrates that WAN-in-Lab does indeed provide different
(and hopefully more realistic) results from those of emulated experiments.

During the experiments, it was found that Reno's window seemed to reduce by more
than half on many occasions, and that for some parameter settings (notably with
small $\alpha$), up to 15\% of all losses resulted in timeouts.  The reason for
this is still under investigation, but may be related to the significant
packet reordering which occurs when traffic shaping is enabled on the routers.

A consequence of this was that loss synchronisation became important.  If links
1 and 3 are bottlenecked, but the Reno flows simultaneously reduce their
windows, then FAST will rapidly respond, and the equilibrium will revert to
link 2 being the bottleneck.  To enable links 1 and 3 to be stably
bottlenecked, most drops had to be random drops, requiring a larger p\_drop.

Drop probability 1 after max threshold, not constant at 1/denom means
smaller-than-expected denom needed to avoid synchronisation
{\bf Was that an issue when DummyNet / NS2 was used?}

RED denominator $\le$ 255

RED max-threshold - min-threshold a power of 2 on some routers
\end{subsubsection}

\end{subsection}

\end{section}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{section}{Project Description {\bf FINISH? Remove?} }
The WAN-in-Lab project consists of the implementation of the
infrastructure described in the previous section, and the use of it
for the development, testing and evaluation of TCP-like protocols.
The initial phase, assembling the core hardware, is largely complete.
The three remaining phases are (i) completing the software infrastructure
to allow end-users to conduct experiments with minimal impact on one
another and with minimal knowledge of the specific hardware  (ii)
enhancing the features of the network, by improving the monitoring
ability, external connectivity and internal connectivity to expand the
range of topologies that can be studied  (iii) testing the hardware and
software by performing actual protocol research; this will be in the form
of a benchmark suite to determine strengths and weaknesses of proposed
TCP protocols, with the aim of selecting a replacement for the current
TCP NewReno.

\end{section}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{section}{Indicators of Success and Major Accomplishments}
The basic WAN-in-Lab hardware is fully installed and operational.  It is
now waiting on the software infrastructure to become fully operational.

The software infrastructure is also taking shape.  Servers can be manually
allocated to projects by means of an interactive web interface, and the
interconnectivity can be controlled using an intuitive web interface
to a gigabit Ethernet switch.  Virtualization of important portions of
the filesystem allows the servers to be configured separately for each
project, protecting users from inadvertent reconfiguration by other users
and allowing servers to be reconfigured easily for different projects.

The software infrastructure now allows the bandwidth, buffer size and
delay of each OC48 link to be set without needing to detailed knowledge
of router configuration.

\end{section}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{section}{Future and Strategic Directions}
Monitoring, complexity, out of band {\bf FINISH}

Both the hardware and software of WAN-in-Lab are still evolving.  The
management software in particular requires work.  As an increasing number
of independent projects start using WAN-in-Lab, there is increased need
for automated resource allocation, and time-sharing on finer timescales,
such as days or hours rather than weeks.  This may involve the adoption of
the eWAN framework developed at INRIA~\cite{eWAN} and Caltech's MonALISA
framework~\cite{MonALISA}.

Another strategic goal is to connect WAN-in-lab to the Ultralight
10 Gbit/s experimental\slash production network~\cite{UltraLight}.
This will allow the
monitoring facilities of WAN-in-Lab to study real-world traffic, allow
studies of incremental deployment of protocols, and increase the range
of topologies available to WAN-in-Lab.

Arrangements are also being made to attach measurement equipment (DAG
cards) to the routers, to allow the detailed measurement of queue sizes
and the burstiness of data.

\begin{subsection}{Benchmarking}
Going forward, our own research using WAN-in-lab will be into benchmarking
the many proposed TCP variants.  The goal is to provide a web site to
which a developer of a new protocol can submit a patch relative to a
recent Web100-enabled Linux kernel, select from a standard set of tests,
and then receive a comparison of the performance of the new protocol
against existing protocols.

While WAN-in-Lab will provide a standard platform for all researchers to use to compare their results, it is only one point in the price-abstraction tradeoff.  We encourage the operators of networks based on emulated links to implement the same tests, to investigate the difference in performance that may result from using real delays.

This will also require a standardized set of traffic generation tools,
which will need to keep sufficient statistics.  Updates to the software
infrastructure will be driven primarily by this research.
\end{subsection}

\end{section}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{section}{Conclusions}
If room {\bf FINISH}
\end{section}

\begin{section}{Acknowledgements}
We acknowledge the use of Caltech's WAN in Lab facility funded by NSF (through
grant EIA-0303620), Cisco ARTI, ARO (through grant W911NF-04-1-0095), and
Corning.
\end{section}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{10}

\bibitem{FAST-NW} C. Jin, D. X. Wei, S. H. Low, G. Buhrmaster, J. Bunn, D. H.
Choe, R. L. A. Cottrell, J. C. Doyle, W. Feng, O. Martin, H. Newman, F.
Paganini, S. Ravot, and S. Singh. ``FAST TCP: From theory to experiments''.
{\it IEEE Network}, 19(1):4-11, 2005.

\bibitem{FAST-INFOCOM} C. Jin, D. X. Wei, and S. H. Low. ``TCP FAST:
Motivation, architecture, algorithms, performance''. In {\it Proceedings of
IEEE Infocom}, March 2004. http://netlab.caltech.edu.

\bibitem{HSTCP} S. Floyd. ``HighSpeed TCP for large congestion windows''. Internet draft draft-floyd-tcp-highspeed-02.txt, work in progress, http://www.icir.org/floyd/hstcp.html, February 2003.

\bibitem{HTCP} R. N. Shorten and D. J. Leith. ``H-TCP: TCP for high-speed and
long-distance networks''. in {\it Proc. PFLDnet}, Argonne, 2004. http://hamilton.ie/net/htcp3.pdf.

\bibitem{STCP} T. Kelly. ``Scalable TCP: Improving performance in highspeed
wide area networks''. {\it Computer Communication Review}, 32(2), April 2003.	
http://www-lce.eng.cam.ac.uk/ctk21/scalable/.

\bibitem{BIC} L. Xu, K. Harfoush, and I. Rhee. ``Binary increase congestion
control for fast long distance networks''. In {\it Proc. INFOCOM}, March 2004.

\bibitem{ARENO} H. Shimonish, T.  Hama and T. Murase, ``TCP-Adaptive Reno for
Improving Efficiency-Friendliness Tradeoffs of TCP Congestion Control
Algorithm'', In {\it Proc. PFLDnet}, Feb. 2006, pp 87-91.

\bibitem{MaxNet} B. Wydrowski, L. L. H. Andrew, and M. Zukerman, ``MaxNet: A
congestion control architecture for scalable networks'', {\it IEEE Commun. Lett.}, 7:511513, Oct. 2003.

\bibitem{Emulab} B. White, J. Lepreau, L. Stoller, R. Ricci, S. Guruprasad, M. Newbold,
M. Hibler, C. Barb and A. Joglekar, ``An Integrated Experimental Environment
for Distributed Systems and Networks'', In {\it Proc. Fifth Symp. Operating
Systems Design and Implementation}. Dec. 2002, pp. 255270.	 http://www.emulab.net/.

\bibitem{Heterogeneous}A. Tang, D. Wei, S. H. Low and M. Chiang.
``Heterogeneous Congestion Control: Efficiency, Fairness and Design''
in {\it Proceedings of IEEE International Conference on Network Protocols
(ICNP)}, 12-15 Nov 2006.

\bibitem{eWAN} http://www.ens-lyon.fr/LIP/RESO/software/EWAN/.

\bibitem{MonALISA} MonALISA web page, http://monalisa.cern.ch/MONALISA/.

\bibitem{UltraLight} Ultralight: An ultrascale information system for data intensive research.	 http://www.ultralight.org.

\end{thebibliography}
\end{document}
